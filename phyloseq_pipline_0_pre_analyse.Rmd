---
title: "pro1_cucumberZ_bac"
author: "wentao"
date: "2019年4月15日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
```

### 2. 基于数据处理结果的整体总计分析
- 提供多种传统流程转化phyloseq的方式，方便使用后续流程。
- 提供将追踪序列文件可视化的代码；
- 基于phyloseq对样品和OTU使用多种标准进行过滤（目前是我见过最为方便的过滤方式）；
- 使用代码直接书写文章中扩增子部分结果分析的基本统计部分的段落内容。

```{R eval=FALSE, include=FALSE}
metadata <- import_qiime_sample_data("./mapping.txt")
dim(metadata)
head(metadata)
colnames(metadata)[1] <- "ID"

sample_data(ps) = metadata

saveRDS(ps,"./a3_DADA2_table/ps.rds")
saveRDS(ps,"./ps.rds")

```


### 原始序列处理过程的track分析，统计序列数量的变化
track文件即为序列追踪文件，追踪每个步骤保留序列的数量
本track使用的是R全套原始数据处理流程。


```{r track, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
library("phyloseq")
track = read.delim("./a9_sum_and_track/dada2_track.txt")

ps = readRDS("./a3_DADA2_table/ps.rds")
design = as.data.frame(sample_data(ps))
head(design)
index = merge(track,design[,c("ID","SampleType")],by = "row.names",all = F)
head(index)
row.names(index) = index$Row.names
index$Row.names  = NULL
library(reshape2)
library("ggplot2")
track_l<- melt(index, id.vars=c("ID","SampleType"),value.name = "value")

head(track_l)
p = ggplot(track_l,aes(x = variable,y = value, fill = ID,color = SampleType)) +
  geom_line(aes(group = ID,color = SampleType))+
  geom_point(pch = 21,size = 3,color = "black")+
  labs(x = "step", y = "count")

  
p = p +theme_bw()+
  #theme_classic()+
  # scale_color_brewer( guide = guide_legend(title = NULL))+
  # scale_fill_brewer(guide = guide_legend(title = NULL))+
  theme(
    
    panel.grid.major=element_blank(),
    panel.grid.minor=element_blank(),
    
    plot.title = element_text(vjust = -8.5,hjust = 0.1),
    axis.title.y =element_text(size = 20,face = "bold",colour = "black"),
    axis.title.x =element_text(size = 24,face = "bold",colour = "black"),
    axis.text = element_text(size = 20,face = "bold"),
    axis.text.x = element_text(colour = "black",size = 14),
    axis.text.y = element_text(colour = "black",size = 14),
    legend.text = element_text(size = 15,face = "bold"))+
  #theme(legend.position = c(0.1,0.2))+
  
  theme(strip.text.x = element_text(size=15, angle=0),
        strip.text.y = element_text(size=12, face="bold"),
        strip.background = element_rect(colour="blue", fill="#CCCCFF"))+
  guides(fill=FALSE)
  # guides(color=FALSE)
p

if (length(unique(track_l$ID))>3){	p=p+theme(axis.text.x=element_text(angle=45,vjust=1, hjust=1))}

ggsave("./a0_track_for_all_count.pdf", p, width = 12, height =6 )


```


### phyloseq对象取子集(样品过滤)


```{R sample or  sampleype, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
###导入原始ps文件
ps = readRDS("./a3_DADA2_table/ps.rds")

##选择count数量大于2000的样品，也就是说将序列数量过少的样品去除，一般不操作，我们肯定弄好才分析。
# ps1 <- prune_samples(sample_sums(ps1) >=2000,ps1);ps0


sample_data(ps)
##method1   phyloseq文件根据sample_data取子集,注意取子集一定要去却一些这些样品中没有的otu
ps_sub <- subset_samples(ps,SampleType %in% c("OF"));ps_sub 
ps_sub <- subset_samples(ps,ID %in% c("SRR8247296"));ps_sub 
ps_sub = filter_taxa(ps_sub, function(x) sum(x ) > 1 , TRUE);ps_sub #筛选序列数量大于1的

#method2  
design = as.data.frame(sample_data(ps))
map1<-design[grep("SRR8247296",row.names(design)),]
ps_sub <- subset_samples(ps,ID %in% map1$ID)
ps_sub = filter_taxa(ps_sub, function(x) sum(x ) > 1 , TRUE)#筛选序列数量大于1的
ps_sub
#是否需要保存
# saveRDS(ps_sub,"./ps_sub.rds")

```

### 读入phyloseq数据并进行原始count整理取舍（过滤OTU）
我们整理完成的ps为原始文件。这个文件导入后还需要做一些事情：
1.对otu表格整理：取舍一些otu或者不同分类等级的数据


```{r 导入原始ps文件, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
ps = readRDS("./a3_DADA2_table//ps.rds")
sample_data(ps)
ps
library("tidyverse")
##如果我们分析细菌数据，可以选择去除非细菌成分，还有我们无法区分的叶绿体和线粒体序列
ps1 <- ps %>%
  subset_taxa(
    Kingdom == "Bacteria" &
      Family  != "mitochondria" &
      Class   != "Chloroplast"
  )
ps1
#去除count值小于1的序列
ps1 = filter_taxa(ps1, function(x) sum(x ) > 1 , TRUE)
ps1
# ##去除在一半样品中出现count数量少于三条的otu
# ps1 = filter_taxa(ps1, function(x) sum(x > 1) > (0.5*length(x)), TRUE);ps1





```

### 标准化phyloseq对象

标准化otu表格有多重方法，这里需要做一个总结，并且要不断完善：
1. 抽平
2.相对丰度标准化
3.log转化
```{r building sub phyloseq, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
ps1 = ps
# 抽平编号：ps11
total = mean(sample_sums(ps1));total
standf = function(x,t = total)round(t*(x/sum(x)))
ps11 = transform_sample_counts(ps1,standf);ps11
saveRDS(ps11, "./ps_rare.rds")
# 相对丰度标准化编号：ps1_rela
ps1_rela  = transform_sample_counts(ps1, function(x) x / sum(x) );ps1_rela 
saveRDS(ps1_rela, "./ps_rela.rds")
#对数标准化编号：ps1_log(添加1是为了方式0的影响)
ps1_log  = transform_sample_counts(ps1, function(x) log(1 + x) );ps1_log
saveRDS(ps1_log, "./ps_log.rds")

```
#### 基于群落数据进行统计分析
准备一份报告，将测序序列数量，otu统计信息，最多的五个门类统计信息等做一个综述。


```{r report, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE}
########基于整体的测序文件我们需要制作测序数据的整体评估###########
ps_sum <- ps1 <- ps
#step_1 ：ps02准备好phyloseq对象并可以使用下面代码来书写群落分析的前四句话。
where <- "soil"
method <- "using 16S rRNA gene amplicon sequencing."
rep = 12
step_1 <- paste("We analyzed the composition of microbial communities in the",where,method)

#step_2 统计每个样品中的序列数量
repead <- paste("For this analysis, we collected",rep,"repeats for each samples from culture",sep = "")
each_count <- paste(repead,"We obtained an average read count per sample of ",round(mean(sample_sums(ps1)),0),"(standard deviation (SD)",round(sd(sample_sums(ps1)),2),").",sep = "")
each_count 
#step_3 统计每个样品中的OTU数量
vegan_otu <-  function(physeq){
  OTU <-  otu_table(physeq)
  if(taxa_are_rows(OTU)){
    OTU <-  t(OTU)
  }
  return(as(OTU,"matrix"))
}
aa = vegan_otu(ps1)
otu_table = as.data.frame(t(aa))
otu_table = as.matrix(otu_table)
otu_table [otu_table > 0] <-1
OTU_sum <- colSums(otu_table)
sample_tax <- paste("the numbers of OTU, generally ranged between ",
                    min(OTU_sum)," and ",max(OTU_sum)," per sample with an average of ",
                    round(mean(OTU_sum),0),"(SD ",round(sd(OTU_sum)),")",sep = "")
sample_tax 

###step 4 统计门水平的总体丰度信息
library("tidyverse")
Taxonomies <- ps1 %>%
  tax_glom(taxrank = "Phylum") %>% 
  transform_sample_counts(function(x) {x/sum(x)} )%>% 
  psmelt() %>%
  #filter(Abundance > 0.05) %>%
  arrange(Phylum)
iris_groups<- group_by(Taxonomies, Phylum)
ps0_sum <- summarise(iris_groups, mean(Abundance), sd(Abundance))
ps0_sum[is.na(ps0_sum)] <- 0
head(ps0_sum)
colnames(ps0_sum) = c("ID","mean","sd")
ps0_sum <- arrange(ps0_sum,desc(mean))
ps0_sum$mean <- ps0_sum$mean *100
ps0_sum <- as.data.frame(ps0_sum)
a = paste(ps0_sum[1,1],"(",round(ps0_sum[1,2],2),"%"," with sd ",round(ps0_sum[1,3],3),")",sep = "")
b = paste(ps0_sum[2,1],"(",round(ps0_sum[2,2],2),"%"," with sd ",round(ps0_sum[2,3],3),")",sep = "")
c = paste(ps0_sum[3,1],"(",round(ps0_sum[3,2],2),"%"," with sd ",round(ps0_sum[3,3],3),")",sep = "")
d = paste(ps0_sum[4,1],"(",round(ps0_sum[4,2],2),"%"," with sd ",round(ps0_sum[4,3],3),")",sep = "")
e = paste(ps0_sum[5,1],"(",round(ps0_sum[5,2],2),"%"," with sd ",round(ps0_sum[5,3],3),")",sep = "")
tax_sum = paste("The majority of OTU belonged to the phyla",a,b,c,d,"and",e,".",sep = " ")

##all_first 
line = paste(step_1,each_count ,sample_tax ,tax_sum,sep = "")
line

write.table(line,"./a9_sum_and_track/microbiome_first_line.txt",quote = F)
```



### 导入数据（提供多种导入数据方式）

#### 第一种
这里提供从普通txt数据导入成为phyloseq的代码：
注意：
默认的otu_table为otu在行名，如果反向，则需指定taxa_are_rows = F，mapping文件需要有一列样品名，并且行名为样品名
```{r this time no use, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
###
library("phyloseq")
OTU_tax = read.table("./a3_DADA2_table/otu_table_tax.txt",sep="\t",row.names = 1,header = T,comment.char="") 
OTU_tax$SeqID = NULL
dim(OTU_tax)[2]
OTU_a = ncol(OTU_tax)-7
seqtab.nochim  = t(OTU_tax[1:OTU_a])
str(seqtab.nochim)
seqtab.nochim = as.matrix(seqtab.nochim)
#tax文件制作
taxa = OTU_tax[-c(1:OTU_a)]
taxa = as.matrix(taxa)
mapping = read.delim("./mapping.txt")
row.names(mapping) = mapping$SampleID

ps = phyloseq(otu_table(seqtab.nochim,taxa_are_rows = F), 
               sample_data(mapping), 
               tax_table(taxa))
ps

saveRDS(ps, "./ps.rds")

```
### 提供Qiime输出导入phyloseq的流程

```{r cars, eval=FALSE, include=FALSE}
#清空内存#######
rm(list=ls()) 
library("phyloseq")
library("ggplot2")
library("dada2")
library("tidyverse")
# ###制作phyloseq对象并保
aa = "~/Desktop/DATA_get_wilt/a3_together_result_gg135/merged190604//a9_usearch_otu_table//otu_table_tax_phylosep.txt"
aab = import_qiime(aa)


metadata <- import_qiime_sample_data("./mapping.txt")
dim(metadata)
head(metadata)


colnames(metadata)[1] <- "ID"
metadata$ID

# match(sample_names(aab),metadata$ID)
# setdiff(sample_names(aab),metadata$ID)
# setdiff(metadata$ID,sample_names(aab))


#colnames(tax_table(China_phyloseq))<- c("Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")
tree = import_qiime(treefilename = "./merged190604//a9_tree/rep_set.tree")

ps <- merge_phyloseq(metadata, aab,tree)
ps

saveRDS(ps, "./ps.rds")


```


<!-- ```{r name, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE} -->

<!-- ``` -->

<!-- ```{r name, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE} -->

<!-- ``` -->








